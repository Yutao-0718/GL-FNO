{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import sys\n",
    "from astropy.io import fits\n",
    "from torch.utils.data.dataset import Subset\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms.functional import normalize\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import torch.nn.functional as F\n",
    "from neuralop.losses.data_losses import LpLoss, H1Loss\n",
    "from neuralop.utils import count_model_params\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97a31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, hdf5_file_path):\n",
    "        self.hdf5_file_path = hdf5_file_path\n",
    "        self.hdf5_file = h5py.File(hdf5_file_path, 'r')\n",
    "        self.dataset_length = len(self.hdf5_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'x': torch.from_numpy(self.hdf5_file[f'sample_{idx}/x'][:]),\n",
    "            'y': torch.from_numpy(self.hdf5_file[f'sample_{idx}/y'][:])\n",
    "        }\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0ff990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.rnn = nn.GRUCell(256, 256)\n",
    "        self.linear = nn.Linear(256, 504 * 504)\n",
    "\n",
    "    def forward(self, x, seq_length=99):\n",
    "        outputs = []\n",
    "        batch_size = x.size(0)\n",
    "        h_t = torch.zeros(batch_size, 256).to(x.device)  # Initial hidden state\n",
    "\n",
    "        for _ in range(seq_length):\n",
    "            x = h_t  # Use the previous hidden state as input\n",
    "            h_t = self.rnn(x, h_t)  # Update the hidden state\n",
    "            output_t = self.linear(h_t)\n",
    "            outputs.append(output_t.view(-1, 1, 504, 504))\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "\"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Use LSTMCell for the recurrent network part\n",
    "        self.lstm = nn.LSTMCell(256, 256)\n",
    "        # Linear layer to map the hidden state output of the LSTM to the desired output size\n",
    "        self.linear = nn.Linear(256, 504 * 504)\n",
    "\n",
    "    def forward(self, x, seq_length=99):\n",
    "        outputs = []\n",
    "        batch_size = x.size(0)\n",
    "        # Initialize hidden and cell states for LSTM\n",
    "        h_t = torch.zeros(batch_size, 256).to(x.device)\n",
    "        c_t = torch.zeros(batch_size, 256).to(x.device)\n",
    "\n",
    "        for _ in range(seq_length):\n",
    "            x = h_t  # Use the previous hidden state as input\n",
    "            # Update the hidden and cell states\n",
    "            h_t, c_t = self.lstm(x, (h_t, c_t))\n",
    "            # Map the hidden state to the output size and reshape to image dimensions\n",
    "            output_t = self.linear(h_t)\n",
    "            outputs.append(output_t.view(-1, 1, 504, 504))\n",
    "\n",
    "        # Concatenate the outputs along the sequence dimension\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5875f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = \"/data.h5\"\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Create the custom dataset\n",
    "custom_dataset = CustomDataset(hdf5_file_path=processed_data_path)\n",
    "\n",
    "# Define the size for the test set\n",
    "test_set_size = 20\n",
    "\n",
    "# Generate random indices for the test set and corresponding training set\n",
    "all_indices = list(range(len(custom_dataset)))\n",
    "random.shuffle(all_indices)\n",
    "\n",
    "test_indices = all_indices[:test_set_size]\n",
    "train_indices = all_indices[test_set_size:]\n",
    "\n",
    "# Create training dataset using Subset\n",
    "train_dataset = Subset(custom_dataset, train_indices)\n",
    "\n",
    "# Create testing dataset using Subset\n",
    "test_dataset = Subset(custom_dataset, test_indices)\n",
    "\n",
    "# Example usage in a DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0, persistent_workers=False)\n",
    "test_loaders = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=0, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bad508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = EncoderDecoder()\n",
    "model = model.to(device)\n",
    "\n",
    "n_params = count_model_params(model)\n",
    "print(f'\\nYour model has {n_params} parameters.')\n",
    "sys.stdout.flush()  # flush the stdout buffer\n",
    "\n",
    "h1loss = H1Loss(d=2)\n",
    "test_loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=2, verbose=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "epoch_durations = []\n",
    "\n",
    "num_epochs = 300\n",
    "print_frequency = 40\n",
    "save_checkpoint_interval = 300\n",
    "checkpoint_dir = \"/result\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    #training process\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = sample['x'].to(device), sample['y'].to(device)\n",
    "        output = model(data)\n",
    "        loss = h1loss(output, target)\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        if batch_idx % print_frequency == 0:\n",
    "            print(f'Train Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # testing process\n",
    "    model.eval()\n",
    "    epoch_test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loaders:\n",
    "            data, target = sample['x'].to(device), sample['y'].to(device)\n",
    "            output = model(data)\n",
    "            loss = test_loss(output, target)\n",
    "            loss = loss.mean()\n",
    "            epoch_test_loss += loss.item()\n",
    "    \n",
    "    avg_test_loss = epoch_test_loss / len(test_loaders)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    epoch_durations.append(epoch_duration)\n",
    "\n",
    "    # Updated learning rate\n",
    "    scheduler.step(avg_train_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Duration: {epoch_duration:.2f}s, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "    # save checkpoint\n",
    "    if (epoch + 1) % save_checkpoint_interval == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}: {checkpoint_path}\")\n",
    "\n",
    "# average time of epoch duration\n",
    "avg_epoch_duration = np.mean(epoch_durations)\n",
    "print(f'Average Epoch Duration: {avg_epoch_duration:.2f}s')\n",
    "\n",
    "# save loss\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses.npy'), np.array(train_losses))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses.npy'), np.array(test_losses))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test_losses, label='Testing Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Testing Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sample_r2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in test_loaders:\n",
    "        x = sample['x'].to(device)\n",
    "        y_true_batch = sample['y'].numpy()\n",
    "        y_pred_batch = model(x).cpu().numpy()\n",
    "\n",
    "        # Calculate R-squared for each sample in the batch\n",
    "        for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "            sample_r2_scores = r2_score(true_sample.flatten(), pred_sample.flatten())\n",
    "            sample_r2.append(sample_r2_scores)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store all sample relative errors\n",
    "sample_relative_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in test_loaders:\n",
    "        x = sample['x'].to(device)\n",
    "        y_true_batch = sample['y'].numpy()\n",
    "        y_pred_batch = model(x).cpu().numpy()\n",
    "\n",
    "        # Calculate Relative Error for each sample in the batch\n",
    "        for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "            absolute_error = np.linalg.norm(true_sample.flatten() - pred_sample.flatten(), 2)\n",
    "            relative_error = absolute_error / (np.linalg.norm(true_sample.flatten(), 2)) \n",
    "            #print(relative_error)\n",
    "            sample_relative_errors.append(relative_error)\n",
    "            \n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "min_mse_sample = None\n",
    "sample_mses = []  # Initialize outside the loop\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample_idx, sample in enumerate(test_loaders):\n",
    "        x = sample['x'].to(device)\n",
    "        y_true_batch = sample['y'].numpy()  \n",
    "        y_pred_batch = model(x).cpu().numpy()\n",
    "\n",
    "        # Iterate through each ground truth-prediction pair in the sample\n",
    "        for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "            mse_sample = mean_squared_error(true_sample.flatten(), pred_sample.flatten())\n",
    "            sample_mses.append(mse_sample)\n",
    "\n",
    "# Calculate overall Mean Squared Error\n",
    "overall_mse = np.mean(sample_mses)\n",
    "print(f'Overall Mean Squared Error: {overall_mse}')\n",
    "\n",
    "# Find the minimum MSE value and its index\n",
    "min_sample_mse = min(sample_mses)\n",
    "min_index = np.argmin(sample_mses)\n",
    "\n",
    "#print(f'Index of Minimum MSE: {min_index}')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store all sample absolute errors\n",
    "sample_absolute_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in test_loaders:\n",
    "        x = sample['x'].to(device)\n",
    "        y_true_batch = sample['y'].numpy()\n",
    "        y_pred_batch = model(x).cpu().numpy()\n",
    "\n",
    "        # Calculate Absolute Error for each sample in the batch\n",
    "        for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "            absolute_error = np.mean(np.abs(true_sample.flatten() - pred_sample.flatten()))\n",
    "            sample_absolute_errors.append(absolute_error)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = np.mean(sample_absolute_errors)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "\n",
    "# Calculate overall Relative Error\n",
    "overall_relative_error = np.mean(sample_relative_errors)\n",
    "print(f'Overall Relative Error: {overall_relative_error}')\n",
    "\n",
    "# Calculate overall R-squared\n",
    "overall_r2 = np.mean(sample_r2)\n",
    "print(f'Overall R-squared: {overall_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ad110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
